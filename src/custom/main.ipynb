{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T00:08:21.132266Z",
     "start_time": "2024-12-11T00:08:20.830915Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ],
   "id": "4336ff7880487aa4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: nvidia-smi\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T00:08:31.324558Z",
     "start_time": "2024-12-11T00:08:31.318669Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from psutil import virtual_memory\n",
    "ram_gb = virtual_memory().total / 1e9\n",
    "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "\n",
    "if ram_gb < 20:\n",
    "  print('Not using a high-RAM runtime')\n",
    "else:\n",
    "  print('You are using a high-RAM runtime!')"
   ],
   "id": "143a26b6e93d14b0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your runtime has 17.2 gigabytes of available RAM\n",
      "\n",
      "Not using a high-RAM runtime\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-11T00:06:02.756573Z",
     "start_time": "2024-12-11T00:05:37.442196Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device = mps\n",
      "Configurations: {'batch_size': 1, 'learning_rate': 0.0001, 'reg': 0, 'epochs': 100, 'steps': [6, 8], 'warmup': 0, 'momentum': 0.9, 'gamma': 1, 'model_type': 'simpleYOLO', 'data_type': 'kitti', 'num_classes': 4, 'training_split_percentage': 0.8, 'dataset_percentage': 0.5, 'save_delay_percent': 0, 'device': 'mps'}\n",
      "\n",
      "Directory /Users/matthewarnold/Documents/School/OMSCS-GATech/Fall2024/CS 7643 - Deep Learning/Final Project/DL_project/dataset already exists. No download needed.\n",
      " ** If dataset has been corrupted, delete the dataset folder to trigger re-download.**\n",
      "\n",
      "Training epoch 0\n",
      "Epoch: [0/100][0/2978] | Time 14.08 (14.08) | Loss 46.84 (46.84) | bboxL 3.14 (3.14) | confL 2.17 (2.17) | backgndL 41.53 (41.53) | clsL -0.00 (0.00) | F1 0.00 (0.00)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[0;32m~/Documents/School/OMSCS-GATech/Fall2024/CS 7643 - Deep Learning/Final Project/DL_project/src/custom/train.py:16\u001B[0m\n\u001B[1;32m     13\u001B[0m solver \u001B[38;5;241m=\u001B[39m SolverKitti(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m     15\u001B[0m \u001B[38;5;66;03m# Train model\u001B[39;00m\n\u001B[0;32m---> 16\u001B[0m solver\u001B[38;5;241m.\u001B[39mtrain()\n",
      "File \u001B[0;32m~/Documents/School/OMSCS-GATech/Fall2024/CS 7643 - Deep Learning/Final Project/DL_project/src/custom/solver_kitti.py:144\u001B[0m, in \u001B[0;36mSolverKitti.train\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    142\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTraining epoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    143\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[0;32m--> 144\u001B[0m loss, specific_losses \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mMainLoop(epoch, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_loader) \u001B[38;5;66;03m# run the main loop of training to get the loss\u001B[39;00m\n\u001B[1;32m    146\u001B[0m \u001B[38;5;66;03m# Validate\u001B[39;00m\n\u001B[1;32m    147\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mValidating epoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/School/OMSCS-GATech/Fall2024/CS 7643 - Deep Learning/Final Project/DL_project/src/custom/solver_kitti.py:236\u001B[0m, in \u001B[0;36mSolverKitti.MainLoop\u001B[0;34m(self, epoch, data_loader)\u001B[0m\n\u001B[1;32m    233\u001B[0m start_batch \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m    235\u001B[0m \u001B[38;5;66;03m# Compute outputs, losses, and f1 score\u001B[39;00m\n\u001B[0;32m--> 236\u001B[0m out, loss, batch_f1Score, specific_losses \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mComputeLossAccUpdateParams(images, targets)\n\u001B[1;32m    238\u001B[0m bboxLoss, confidenceLoss, backgroundLoss, classScoreLoss \u001B[38;5;241m=\u001B[39m specific_losses\n\u001B[1;32m    240\u001B[0m \u001B[38;5;66;03m# Update metrics\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/School/OMSCS-GATech/Fall2024/CS 7643 - Deep Learning/Final Project/DL_project/src/custom/solver_kitti.py:337\u001B[0m, in \u001B[0;36mSolverKitti.ComputeLossAccUpdateParams\u001B[0;34m(self, data, target)\u001B[0m\n\u001B[1;32m    334\u001B[0m output \u001B[38;5;241m=\u001B[39m pred\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_size, \u001B[38;5;241m114\u001B[39m, num_anchors, bbox_coords \u001B[38;5;241m+\u001B[39m conf_measure \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_classes)\n\u001B[1;32m    336\u001B[0m \u001B[38;5;66;03m# Calculate loss\u001B[39;00m\n\u001B[0;32m--> 337\u001B[0m loss, f1_score, specific_losses \u001B[38;5;241m=\u001B[39m compute_loss(output, target, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_classes)\n\u001B[1;32m    339\u001B[0m \u001B[38;5;66;03m# Main backward pass to Update gradients\u001B[39;00m\n\u001B[1;32m    340\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n",
      "File \u001B[0;32m~/Documents/School/OMSCS-GATech/Fall2024/CS 7643 - Deep Learning/Final Project/DL_project/src/custom/evalutation.py:32\u001B[0m, in \u001B[0;36mcompute_loss\u001B[0;34m(predictions, targets, num_classes)\u001B[0m\n\u001B[1;32m     29\u001B[0m pred_single \u001B[38;5;241m=\u001B[39m predictions[singleImageFrameIdx] \u001B[38;5;66;03m# (num_cells, num_anchors, 9)\u001B[39;00m\n\u001B[1;32m     30\u001B[0m target_single \u001B[38;5;241m=\u001B[39m targets[singleImageFrameIdx]  \u001B[38;5;66;03m# (N_objects, 5)\u001B[39;00m\n\u001B[0;32m---> 32\u001B[0m single_loss, single_f1Score, specific_losses \u001B[38;5;241m=\u001B[39m compute_loss_single_image(\n\u001B[1;32m     33\u001B[0m     pred_single, target_single, num_classes\n\u001B[1;32m     34\u001B[0m )\n\u001B[1;32m     36\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m singleImageFrameIdx \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m     37\u001B[0m     total_loss_batch \u001B[38;5;241m=\u001B[39m single_loss\n",
      "File \u001B[0;32m~/Documents/School/OMSCS-GATech/Fall2024/CS 7643 - Deep Learning/Final Project/DL_project/src/custom/evalutation.py:223\u001B[0m, in \u001B[0;36mcompute_loss_single_image\u001B[0;34m(predictions, targets, num_classes, img_size, grid_h, grid_w, conf_threshold, iou_threshold)\u001B[0m\n\u001B[1;32m    220\u001B[0m conf_loss_noobj \u001B[38;5;241m=\u001B[39m bce_loss_conf(predictions[noobj_mask][\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m, \u001B[38;5;241m4\u001B[39m], target_tensor[noobj_mask][\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m, \u001B[38;5;241m4\u001B[39m])\n\u001B[1;32m    222\u001B[0m \u001B[38;5;66;03m# Class loss\u001B[39;00m\n\u001B[0;32m--> 223\u001B[0m class_loss \u001B[38;5;241m=\u001B[39m bce_loss_class(predictions[obj_mask][\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m, \u001B[38;5;241m5\u001B[39m:\u001B[38;5;241m5\u001B[39m\u001B[38;5;241m+\u001B[39mnum_classes], target_tensor[obj_mask][\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m, \u001B[38;5;241m5\u001B[39m:\u001B[38;5;241m5\u001B[39m\u001B[38;5;241m+\u001B[39mnum_classes])\n\u001B[1;32m    225\u001B[0m \u001B[38;5;66;03m# Weights for each component of the loss function, currently evenly weighted\u001B[39;00m\n\u001B[1;32m    226\u001B[0m \u001B[38;5;66;03m# lambda_boundingBoxes = 0.5\u001B[39;00m\n\u001B[1;32m    227\u001B[0m \u001B[38;5;66;03m# lambda_confidence = 100.0\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    230\u001B[0m \n\u001B[1;32m    231\u001B[0m \u001B[38;5;66;03m# These are similar to the weights that the YOLO paper uses\u001B[39;00m\n\u001B[1;32m    232\u001B[0m lambda_boundingBoxes \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m7\u001B[39m\n",
      "File \u001B[0;32m~/miniconda3/envs/cs7643-finalProj/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/miniconda3/envs/cs7643-finalProj/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/cs7643-finalProj/lib/python3.12/site-packages/torch/nn/modules/loss.py:1179\u001B[0m, in \u001B[0;36mCrossEntropyLoss.forward\u001B[0;34m(self, input, target)\u001B[0m\n\u001B[1;32m   1178\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor, target: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m-> 1179\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mcross_entropy(\u001B[38;5;28minput\u001B[39m, target, weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight,\n\u001B[1;32m   1180\u001B[0m                            ignore_index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mignore_index, reduction\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreduction,\n\u001B[1;32m   1181\u001B[0m                            label_smoothing\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlabel_smoothing)\n",
      "File \u001B[0;32m~/miniconda3/envs/cs7643-finalProj/lib/python3.12/site-packages/torch/nn/functional.py:3059\u001B[0m, in \u001B[0;36mcross_entropy\u001B[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001B[0m\n\u001B[1;32m   3057\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m size_average \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m reduce \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   3058\u001B[0m     reduction \u001B[38;5;241m=\u001B[39m _Reduction\u001B[38;5;241m.\u001B[39mlegacy_get_string(size_average, reduce)\n\u001B[0;32m-> 3059\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39m_nn\u001B[38;5;241m.\u001B[39mcross_entropy_loss(\u001B[38;5;28minput\u001B[39m, target, weight, _Reduction\u001B[38;5;241m.\u001B[39mget_enum(reduction), ignore_index, label_smoothing)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 1,
   "source": "%run train.py",
   "id": "initial_id"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "%run inference.py",
   "id": "75ac554349ffd1f6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
